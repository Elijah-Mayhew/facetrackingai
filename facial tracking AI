import cv2
import numpy as np

# Initialize the Kalman filter
kalman = cv2.KalmanFilter(4, 2, 0)
kalman.measurementMatrix = np.array([[1, 0, 0, 0], [0, 1, 0, 0]], np.float32)
kalman.transitionMatrix = np.array([[1, 0, 1, 0], [0, 1, 0, 1], [0, 0, 1, 0], [0, 0, 0, 1]], np.float32)
kalman.processNoiseCov = np.array([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0], [0, 0, 0, 1]], np.float32) * 0.03

# Load the cascade classifier
face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')

# Load the video
cap = cv2.VideoCapture(0)

# Initialize the variables for tracking
face_detected = False
measurement = np.array((2, 1), np.float32)
prediction = np.zeros((2, 1), np.float32)

while True:
    # Read a frame from the video
    ret, frame = cap.read()

    # Convert the frame to grayscale
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

    # Detect the faces in the frame
    faces = face_cascade.detectMultiScale(gray, 1.3, 5)

    # Track the faces using the Kalman filter
    if len(faces) > 0:
        x, y, w, h = faces[0]
        measurement[0, 0] = x + w/2
        measurement[1, 0] = y + h/2
        if not face_detected:
            kalman.statePre = np.array([[x + w/2], [y + h/2], [0], [0]], np.float32)
            kalman.statePost = np.array([[x + w/2], [y + h/2], [0], [0]], np.float32)
            face_detected = True
        else:
            prediction = kalman.predict()
            kalman.correct(measurement)
            cv2.rectangle(frame, (int(prediction[0]), int(prediction[1])), (int(prediction[0])+w, int(prediction[1])+h), (0, 255, 0), 2)

    # Display the video with the faces tracked
    cv2.imshow('Facial Tracking', frame)

    # Exit the loop if the 'q' key is pressed
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Release the video capture and close the windows
cap.release()
cv2.destroyAllWindows()
